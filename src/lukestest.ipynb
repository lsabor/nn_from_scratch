{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import our data\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "# DATA FROM HERE: https://pjreddie.com/projects/mnist-in-csv/\n",
    "file_test = '../data/MNIST/mnist_test.csv'\n",
    "file_train = '../data/MNIST/mnist_train.csv'\n",
    "\n",
    "\n",
    "def get_data_from_csv(file: str) -> Tuple[np.array, int, int]:\n",
    "    \"\"\"takes data from file (csv type) and returns\n",
    "    a shuffled version of the data in an np.array form,\n",
    "    along with two ints:\n",
    "    m - number of test examples\n",
    "    n - number of points per example (including integrated labels)\"\"\"\n",
    "    assert os.path.exists(file), f\"{file} does not exist\"\n",
    "\n",
    "    data = pd.read_csv(file)\n",
    "    m, n = data.shape\n",
    "    data = np.array(data)\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    return (data, m, n)\n",
    "\n",
    "\n",
    "def get_labels_and_data_1st_column(data: np.array) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"takes an np.array of data, returns (Transposed) labels (Y) and data (X)\"\"\"\n",
    "    data = data.T\n",
    "    Y = data[0]\n",
    "    X = data[1:]/255.\n",
    "    return (Y, X)\n",
    "\n",
    "\n",
    "data_test, m_test, n_test = get_data_from_csv(file_test)\n",
    "Y_test, X_test = get_labels_and_data_1st_column(data_test)\n",
    "\n",
    "data_train, m_train, n_train = get_data_from_csv(file_train)\n",
    "Y_train, X_train = get_labels_and_data_1st_column(data_train)\n",
    "\n",
    "\n",
    "\"\"\"making sure that our Y_test/Y_train are actually labels\"\"\"\n",
    "\n",
    "assert Y_test.max() == 9\n",
    "assert Y_train.max() == 9\n",
    "assert X_test[0].max() != 9\n",
    "assert X_train[0].max() != 9\n",
    "\n",
    "\n",
    "def one_hot_encode(Y: np.array, classes = 10):\n",
    "    \"\"\"transforms an array into 1 hot encodings:\n",
    "    [0,3,2] -> [ [1,0,0,0],  [0,0,0,1],  [0,0,1,0] ]\n",
    "    Assumes that max(Y) is the highest possible enconding.\"\"\"\n",
    "    # first instantiate 0's which should be an array of len(Y) max(Y) \n",
    "    one_hot = np.zeros((Y.size,classes))\n",
    "    one_hot[np.arange(Y.size), Y] = 1\n",
    "    one_hot = one_hot.T\n",
    "    return one_hot\n",
    "\n",
    "Y = one_hot_encode(Y_train)\n",
    "X = X_train\n",
    "\n",
    "m = X.shape[1] # number of examples\n",
    "x = X.shape[0] # number of datapoints per sample\n",
    "n = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape = (10, 500)\n",
      "X.shape = (5, 500)\n",
      "2.343816072341479\n",
      "[[0.833 1.087 0.986 ... 0.966 1.091 0.586]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.094 0.    0.    ... 0.033 0.    0.   ]\n",
      " ...\n",
      " [0.107 0.037 0.251 ... 0.191 0.26  0.413]\n",
      " [0.494 0.448 0.627 ... 0.687 0.25  0.998]\n",
      " [0.    0.    0.    ... 0.    0.145 0.   ]]\n",
      "[[0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.27  0.354 0.348 ... 0.245 0.406 0.193]\n",
      " [0.597 0.577 0.464 ... 0.52  0.716 0.459]\n",
      " ...\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.091 0.    0.104 ... 0.135 0.    0.379]\n",
      " [0.358 0.482 0.58  ... 0.542 0.565 0.413]]\n",
      "[[0.076 0.081 0.081 ... 0.078 0.082 0.071]\n",
      " [0.162 0.171 0.183 ... 0.179 0.175 0.168]\n",
      " [0.082 0.081 0.087 ... 0.085 0.077 0.095]\n",
      " ...\n",
      " [0.112 0.106 0.1   ... 0.104 0.108 0.111]\n",
      " [0.056 0.058 0.063 ... 0.061 0.055 0.059]\n",
      " [0.091 0.091 0.092 ... 0.09  0.086 0.089]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Softmax - deriv_loss\n",
      "Y_hat  = array([[0.076, 0.081, 0.081, ..., 0.078, 0.082, 0.071],\n",
      "       [0.162, 0.171, 0.183, ..., 0.179, 0.175, 0.168],\n",
      "       [0.082, 0.081, 0.087, ..., 0.085, 0.077, 0.095],\n",
      "       ...,\n",
      "       [0.112, 0.106, 0.1  , ..., 0.104, 0.108, 0.111],\n",
      "       [0.056, 0.058, 0.063, ..., 0.061, 0.055, 0.059],\n",
      "       [0.091, 0.091, 0.092, ..., 0.09 , 0.086, 0.089]])\n",
      "DZ = array([[ 0.076, -0.919,  0.081, ...,  0.078,  0.082,  0.071],\n",
      "       [-0.838,  0.171, -0.817, ...,  0.179,  0.175,  0.168],\n",
      "       [ 0.082,  0.081,  0.087, ...,  0.085,  0.077,  0.095],\n",
      "       ...,\n",
      "       [ 0.112,  0.106,  0.1  , ...,  0.104,  0.108,  0.111],\n",
      "       [ 0.056,  0.058,  0.063, ...,  0.061,  0.055,  0.059],\n",
      "       [ 0.091,  0.091,  0.092, ...,  0.09 ,  0.086,  0.089]])\n",
      "layer_index = 2, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
      "       [0.27 , 0.354, 0.348, ..., 0.245, 0.406, 0.193],\n",
      "       [0.597, 0.577, 0.464, ..., 0.52 , 0.716, 0.459],\n",
      "       ...,\n",
      "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
      "       [0.091, 0.   , 0.104, ..., 0.135, 0.   , 0.379],\n",
      "       [0.358, 0.482, 0.58 , ..., 0.542, 0.565, 0.413]])\n",
      "DA = array([[-0.129, -0.396, -0.127, ...,  0.128, -0.113, -0.339],\n",
      "       [ 0.052, -0.177,  0.053, ..., -0.237,  0.224,  0.12 ],\n",
      "       [ 0.195,  0.061,  0.175, ..., -0.167, -0.365, -0.092],\n",
      "       ...,\n",
      "       [ 0.086, -0.513,  0.095, ...,  0.352, -0.269, -0.001],\n",
      "       [ 0.077,  0.217,  0.07 , ..., -0.082,  0.198, -0.271],\n",
      "       [-0.452, -0.239, -0.431, ...,  0.144, -0.125,  0.36 ]])\n",
      "DW = array([[ 0.000e+00, -2.602e+00, -4.379e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  3.437e-02,  0.000e+00, -2.008e+00, -4.323e+00],\n",
      "       [ 0.000e+00,  1.310e+01,  2.270e+01,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  3.405e-01,  0.000e+00,  3.567e+00,  1.989e+01],\n",
      "       [ 0.000e+00, -6.190e+00, -1.158e+01,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -3.162e-01,  0.000e+00, -1.957e+00, -9.821e+00],\n",
      "       [ 0.000e+00, -5.096e+00, -1.112e+01,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -2.141e-02,  0.000e+00, -1.188e+00, -6.844e+00],\n",
      "       [ 0.000e+00,  5.151e+00,  9.424e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -9.267e-02,  0.000e+00,  1.602e+00,  7.448e+00],\n",
      "       [ 0.000e+00,  4.618e+00,  7.254e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  1.374e-01,  0.000e+00,  2.018e+00,  7.913e+00],\n",
      "       [ 0.000e+00, -8.604e-01, -7.637e-01,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  7.507e-02,  0.000e+00,  2.865e-01, -6.106e-01],\n",
      "       [ 0.000e+00, -3.509e-01,  1.105e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -8.222e-02,  0.000e+00,  4.728e-01,  6.141e-01],\n",
      "       [ 0.000e+00, -2.843e+00, -5.151e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  8.677e-02,  0.000e+00, -1.007e+00, -5.568e+00],\n",
      "       [ 0.000e+00, -4.928e+00, -7.495e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -1.616e-01,  0.000e+00, -1.785e+00, -8.703e+00]])\n",
      "Db = array([[ -8.972],\n",
      "       [ 39.68 ],\n",
      "       [-19.809],\n",
      "       [-16.289],\n",
      "       [ 15.535],\n",
      "       [ 14.169],\n",
      "       [ -1.446],\n",
      "       [  1.428],\n",
      "       [ -8.903],\n",
      "       [-15.392]])\n",
      "layer_index = 3, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[-0.443, -0.437, -0.338, ..., -0.316, -0.48 , -0.214],\n",
      "       [ 0.27 ,  0.354,  0.348, ...,  0.245,  0.406,  0.193],\n",
      "       [ 0.597,  0.577,  0.464, ...,  0.52 ,  0.716,  0.459],\n",
      "       ...,\n",
      "       [-0.567, -0.697, -0.627, ..., -0.696, -0.662, -0.43 ],\n",
      "       [ 0.091, -0.004,  0.104, ...,  0.135, -0.115,  0.379],\n",
      "       [ 0.358,  0.482,  0.58 , ...,  0.542,  0.565,  0.413]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       ...,\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True, False,  True, ...,  True, False,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True]])\n",
      "DZ = array([[-0.   , -0.   , -0.   , ...,  0.   , -0.   , -0.   ],\n",
      "       [ 0.052, -0.177,  0.053, ..., -0.237,  0.224,  0.12 ],\n",
      "       [ 0.195,  0.061,  0.175, ..., -0.167, -0.365, -0.092],\n",
      "       ...,\n",
      "       [ 0.   , -0.   ,  0.   , ...,  0.   , -0.   , -0.   ],\n",
      "       [ 0.077,  0.   ,  0.07 , ..., -0.082,  0.   , -0.271],\n",
      "       [-0.452, -0.239, -0.431, ...,  0.144, -0.125,  0.36 ]])\n",
      "layer_index = 4, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0.833, 1.087, 0.986, ..., 0.966, 1.091, 0.586],\n",
      "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
      "       [0.094, 0.   , 0.   , ..., 0.033, 0.   , 0.   ],\n",
      "       ...,\n",
      "       [0.107, 0.037, 0.251, ..., 0.191, 0.26 , 0.413],\n",
      "       [0.494, 0.448, 0.627, ..., 0.687, 0.25 , 0.998],\n",
      "       [0.   , 0.   , 0.   , ..., 0.   , 0.145, 0.   ]])\n",
      "DA = array([[ 0.038, -0.116, -0.008, ..., -0.09 ,  0.044,  0.169],\n",
      "       [-0.028,  0.149,  0.082, ..., -0.016, -0.19 , -0.117],\n",
      "       [ 0.067,  0.124,  0.079, ...,  0.041, -0.088, -0.139],\n",
      "       ...,\n",
      "       [-0.046,  0.075,  0.095, ..., -0.124, -0.101,  0.082],\n",
      "       [ 0.308,  0.006,  0.139, ..., -0.034, -0.   , -0.249],\n",
      "       [ 0.053, -0.026, -0.038, ...,  0.027, -0.24 , -0.113]])\n",
      "DW = array([[ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00],\n",
      "       [-3.066e+00,  7.596e-03,  7.429e-03,  0.000e+00,  1.129e-01,\n",
      "        -3.375e-01, -1.485e+00, -5.278e-01, -2.397e+00,  2.650e-01],\n",
      "       [ 1.113e+01,  3.053e-02,  4.569e-02,  0.000e+00,  3.886e-01,\n",
      "         2.365e+00,  5.791e+00,  3.871e+00,  8.694e+00,  2.107e-01],\n",
      "       [ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00],\n",
      "       [ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00],\n",
      "       [ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00],\n",
      "       [-3.410e+00,  0.000e+00, -4.596e-02,  0.000e+00, -7.219e-03,\n",
      "         1.166e-01, -5.660e-01, -2.559e-01, -2.526e+00, -9.460e-02],\n",
      "       [ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00],\n",
      "       [ 1.208e+00,  9.739e-03, -1.089e-01,  0.000e+00, -1.161e-01,\n",
      "         3.035e-01,  1.293e+00,  1.082e-01,  1.335e+00, -1.447e-01],\n",
      "       [ 7.104e+00, -6.681e-02,  2.333e-01,  0.000e+00, -1.813e-01,\n",
      "         6.735e-01, -1.334e-01, -1.315e-01,  1.985e+00, -2.371e-01]])\n",
      "Db = array([[ 0.   ],\n",
      "       [-3.042],\n",
      "       [11.148],\n",
      "       [ 0.   ],\n",
      "       [ 0.   ],\n",
      "       [ 0.   ],\n",
      "       [-4.406],\n",
      "       [ 0.   ],\n",
      "       [ 1.221],\n",
      "       [ 6.493]])\n",
      "layer_index = 5, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[ 0.833,  1.087,  0.986, ...,  0.966,  1.091,  0.586],\n",
      "       [-0.396, -0.41 , -0.676, ..., -0.776, -0.633, -0.397],\n",
      "       [ 0.094, -0.045, -0.151, ...,  0.033, -0.019, -0.181],\n",
      "       ...,\n",
      "       [ 0.107,  0.037,  0.251, ...,  0.191,  0.26 ,  0.413],\n",
      "       [ 0.494,  0.448,  0.627, ...,  0.687,  0.25 ,  0.998],\n",
      "       [-0.024, -0.337, -0.219, ..., -0.284,  0.145, -0.26 ]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[ True,  True,  True, ...,  True,  True,  True],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True, False, False, ...,  True, False, False],\n",
      "       ...,\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [False, False, False, ..., False,  True, False]])\n",
      "DZ = array([[ 0.038, -0.116, -0.008, ..., -0.09 ,  0.044,  0.169],\n",
      "       [-0.   ,  0.   ,  0.   , ..., -0.   , -0.   , -0.   ],\n",
      "       [ 0.067,  0.   ,  0.   , ...,  0.041, -0.   , -0.   ],\n",
      "       ...,\n",
      "       [-0.046,  0.075,  0.095, ..., -0.124, -0.101,  0.082],\n",
      "       [ 0.308,  0.006,  0.139, ..., -0.034, -0.   , -0.249],\n",
      "       [ 0.   , -0.   , -0.   , ...,  0.   , -0.24 , -0.   ]])\n",
      "layer_index = 6, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0.51 , 0.547, 0.484, ..., 0.961, 0.219, 0.642],\n",
      "       [0.426, 0.609, 0.388, ..., 0.356, 0.738, 0.189],\n",
      "       [0.078, 0.052, 0.799, ..., 0.351, 0.931, 0.367],\n",
      "       [0.01 , 0.289, 0.596, ..., 0.079, 0.232, 0.788],\n",
      "       [0.379, 0.876, 0.756, ..., 0.657, 0.705, 0.009]])\n",
      "DA = array([[ 0.125, -0.021, -0.115, ...,  0.071,  0.087, -0.02 ],\n",
      "       [-0.117, -0.006,  0.015, ..., -0.067, -0.173,  0.128],\n",
      "       [-0.016, -0.011, -0.086, ...,  0.023, -0.098,  0.084],\n",
      "       [ 0.079, -0.009, -0.043, ...,  0.009,  0.2  , -0.018],\n",
      "       [-0.032, -0.083, -0.156, ...,  0.078,  0.15 ,  0.095]])\n",
      "DW = array([[ 0.105,  0.492, -0.066, -1.046, -0.738],\n",
      "       [ 0.01 ,  0.154,  0.01 ,  0.143,  0.034],\n",
      "       [-0.226, -0.296, -0.111, -0.165, -0.364],\n",
      "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
      "       [ 0.807,  1.033,  0.775,  1.211,  0.249],\n",
      "       [ 1.581,  0.881, -0.179, -0.173,  2.601],\n",
      "       [-3.297, -1.656, -2.533, -2.257, -0.84 ],\n",
      "       [ 3.512,  2.72 ,  2.964,  3.378,  2.988],\n",
      "       [-0.446, -1.322, -0.458,  0.045, -1.621],\n",
      "       [-0.308, -0.465, -0.651, -0.403, -0.344]])\n",
      "Db = array([[-0.515],\n",
      "       [ 0.18 ],\n",
      "       [-0.944],\n",
      "       [ 0.   ],\n",
      "       [ 1.578],\n",
      "       [ 2.625],\n",
      "       [-2.491],\n",
      "       [ 5.879],\n",
      "       [-2.945],\n",
      "       [-1.429]])\n",
      "14.119451790239486\n",
      "[[1.38  2.197 2.494 ... 1.795 2.045 1.795]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [1.427 1.575 1.479 ... 1.59  1.591 1.138]\n",
      " ...\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [4.879 5.873 5.865 ... 5.753 5.827 4.625]\n",
      " [1.945 1.994 2.559 ... 2.092 2.926 2.013]]\n",
      "[[1.255e+00 1.439e+00 1.983e+00 ... 1.828e+00 1.922e+00 1.765e+00]\n",
      " [2.489e+01 3.212e+01 3.630e+01 ... 3.228e+01 3.263e+01 3.001e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.171e-01 2.276e-02 3.176e-01 ... 3.893e-01 3.276e-01 4.249e-01]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[1.159e-048 5.276e-061 3.066e-067 ... 1.433e-060 2.533e-061 3.216e-056]\n",
      " [8.705e-251 2.685e-315 0.000e+000 ... 1.890e-315 4.238e-319 4.620e-294]\n",
      " [1.000e+000 1.000e+000 1.000e+000 ... 1.000e+000 1.000e+000 1.000e+000]\n",
      " ...\n",
      " [3.906e-076 3.084e-095 8.970e-106 ... 2.514e-095 2.855e-096 5.366e-089]\n",
      " [1.591e-057 4.628e-072 7.847e-080 ... 8.512e-072 5.219e-073 1.191e-066]\n",
      " [4.286e-024 4.237e-030 7.514e-033 ... 1.199e-029 3.684e-030 2.544e-027]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Softmax - deriv_loss\n",
      "Y_hat  = array([[1.159e-048, 5.276e-061, 3.066e-067, ..., 1.433e-060, 2.533e-061,\n",
      "        3.216e-056],\n",
      "       [8.705e-251, 2.685e-315, 0.000e+000, ..., 1.890e-315, 4.238e-319,\n",
      "        4.620e-294],\n",
      "       [1.000e+000, 1.000e+000, 1.000e+000, ..., 1.000e+000, 1.000e+000,\n",
      "        1.000e+000],\n",
      "       ...,\n",
      "       [3.906e-076, 3.084e-095, 8.970e-106, ..., 2.514e-095, 2.855e-096,\n",
      "        5.366e-089],\n",
      "       [1.591e-057, 4.628e-072, 7.847e-080, ..., 8.512e-072, 5.219e-073,\n",
      "        1.191e-066],\n",
      "       [4.286e-024, 4.237e-030, 7.514e-033, ..., 1.199e-029, 3.684e-030,\n",
      "        2.544e-027]])\n",
      "DZ = array([[ 1.159e-048, -1.000e+000,  3.066e-067, ...,  1.433e-060,\n",
      "         2.533e-061,  3.216e-056],\n",
      "       [-1.000e+000,  2.685e-315, -1.000e+000, ...,  1.890e-315,\n",
      "         4.238e-319,  4.620e-294],\n",
      "       [ 1.000e+000,  1.000e+000,  1.000e+000, ...,  1.000e+000,\n",
      "         1.000e+000,  1.000e+000],\n",
      "       ...,\n",
      "       [ 3.906e-076,  3.084e-095,  8.970e-106, ...,  2.514e-095,\n",
      "         2.855e-096,  5.366e-089],\n",
      "       [ 1.591e-057,  4.628e-072,  7.847e-080, ...,  8.512e-072,\n",
      "         5.219e-073,  1.191e-066],\n",
      "       [ 4.286e-024,  4.237e-030,  7.514e-033, ...,  1.199e-029,\n",
      "         3.684e-030,  2.544e-027]])\n",
      "layer_index = 2, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[1.255e+00, 1.439e+00, 1.983e+00, ..., 1.828e+00, 1.922e+00,\n",
      "        1.765e+00],\n",
      "       [2.489e+01, 3.212e+01, 3.630e+01, ..., 3.228e+01, 3.263e+01,\n",
      "        3.001e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       ...,\n",
      "       [1.171e-01, 2.276e-02, 3.176e-01, ..., 3.893e-01, 3.276e-01,\n",
      "        4.249e-01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00]])\n",
      "DA = array([[-0.509, -0.778, -0.509, ..., -0.253, -0.492, -0.719],\n",
      "       [19.512,  3.579, 19.512, ...,  5.262,  1.486, 11.096],\n",
      "       [34.099,  6.886, 34.099, ..., 10.282, -0.285, 18.375],\n",
      "       ...,\n",
      "       [ 0.474, -0.129,  0.474, ...,  0.733,  0.12 ,  0.38 ],\n",
      "       [ 6.006,  0.579,  6.006, ...,  2.572,  1.383,  4.098],\n",
      "       [29.237,  5.222, 29.237, ...,  9.313,  2.812, 18.066]])\n",
      "DW = array([[-8.780e+001, -1.575e+003,  0.000e+000,  2.774e-069, -7.408e+001,\n",
      "        -8.529e+001, -1.476e+003, -1.607e+001,  0.000e+000,  0.000e+000],\n",
      "       [-8.726e+001, -1.528e+003,  0.000e+000,  0.000e+000, -7.537e+001,\n",
      "        -8.497e+001, -1.427e+003, -1.732e+001,  0.000e+000,  0.000e+000],\n",
      "       [ 7.865e+002,  1.412e+004,  0.000e+000,  6.962e-002,  6.385e+002,\n",
      "         7.447e+002,  1.334e+004,  1.420e+002,  0.000e+000,  0.000e+000],\n",
      "       [-9.299e+001, -1.661e+003,  0.000e+000,  2.265e-030, -7.296e+001,\n",
      "        -8.529e+001, -1.590e+003, -1.675e+001,  0.000e+000,  0.000e+000],\n",
      "       [-7.513e+001, -1.377e+003,  0.000e+000,  4.231e-215, -5.695e+001,\n",
      "        -6.918e+001, -1.314e+003, -1.274e+001,  0.000e+000,  0.000e+000],\n",
      "       [-8.497e+001, -1.523e+003,  0.000e+000,  2.929e-203, -6.677e+001,\n",
      "        -7.867e+001, -1.449e+003, -1.543e+001,  0.000e+000,  0.000e+000],\n",
      "       [-8.505e+001, -1.515e+003,  0.000e+000,  4.348e-106, -6.977e+001,\n",
      "        -8.070e+001, -1.431e+003, -1.590e+001,  0.000e+000,  0.000e+000],\n",
      "       [-9.345e+001, -1.688e+003,  0.000e+000,  1.010e-109, -7.592e+001,\n",
      "        -8.875e+001, -1.597e+003, -1.603e+001,  0.000e+000,  0.000e+000],\n",
      "       [-7.275e+001, -1.267e+003,  0.000e+000,  2.319e-082, -6.343e+001,\n",
      "        -7.103e+001, -1.183e+003, -1.422e+001,  0.000e+000,  0.000e+000],\n",
      "       [-1.071e+002, -1.982e+003,  0.000e+000, -6.962e-002, -8.320e+001,\n",
      "        -1.008e+002, -1.874e+003, -1.759e+001,  0.000e+000,  0.000e+000]])\n",
      "Db = array([[-48.],\n",
      "       [-47.],\n",
      "       [438.],\n",
      "       [-54.],\n",
      "       [-43.],\n",
      "       [-49.],\n",
      "       [-47.],\n",
      "       [-52.],\n",
      "       [-38.],\n",
      "       [-60.]])\n",
      "layer_index = 3, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[ 1.255e+00,  1.439e+00,  1.983e+00, ...,  1.828e+00,  1.922e+00,\n",
      "         1.765e+00],\n",
      "       [ 2.489e+01,  3.212e+01,  3.630e+01, ...,  3.228e+01,  3.263e+01,\n",
      "         3.001e+01],\n",
      "       [-1.015e+02, -1.285e+02, -1.463e+02, ..., -1.311e+02, -1.337e+02,\n",
      "        -1.213e+02],\n",
      "       ...,\n",
      "       [ 1.171e-01,  2.276e-02,  3.176e-01, ...,  3.893e-01,  3.276e-01,\n",
      "         4.249e-01],\n",
      "       [-1.188e+01, -1.565e+01, -1.842e+01, ..., -1.630e+01, -1.610e+01,\n",
      "        -1.549e+01],\n",
      "       [-2.346e+01, -3.068e+01, -3.116e+01, ..., -2.684e+01, -2.840e+01,\n",
      "        -2.414e+01]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       ...,\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False]])\n",
      "DZ = array([[-0.509, -0.778, -0.509, ..., -0.253, -0.492, -0.719],\n",
      "       [19.512,  3.579, 19.512, ...,  5.262,  1.486, 11.096],\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.   ,  0.   ],\n",
      "       ...,\n",
      "       [ 0.474, -0.129,  0.474, ...,  0.733,  0.12 ,  0.38 ],\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]])\n",
      "layer_index = 4, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[1.38 , 2.197, 2.494, ..., 1.795, 2.045, 1.795],\n",
      "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
      "       [1.427, 1.575, 1.479, ..., 1.59 , 1.591, 1.138],\n",
      "       ...,\n",
      "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
      "       [4.879, 5.873, 5.865, ..., 5.753, 5.827, 4.625],\n",
      "       [1.945, 1.994, 2.559, ..., 2.092, 2.926, 2.013]])\n",
      "DA = array([[ 73.377,  14.616,  73.377, ...,  21.115,   6.444,  41.105],\n",
      "       [ -5.26 ,  -0.786,  -5.26 , ...,  -1.453,  -0.31 ,  -2.823],\n",
      "       [ -7.064,  -0.989,  -7.064, ...,  -2.028,  -0.284,  -3.964],\n",
      "       ...,\n",
      "       [ 16.047,   3.238,  16.047, ...,   4.146,   1.268,   9.268],\n",
      "       [ 47.553,   9.488,  47.553, ...,  14.144,   4.283,  26.383],\n",
      "       [-12.264,  -2.484, -12.264, ...,  -3.103,  -1.132,  -7.089]])\n",
      "DW = array([[-3.822e+02,  0.000e+00, -2.639e+02,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -1.509e+03,  0.000e+00, -1.019e+03, -4.371e+02],\n",
      "       [ 6.056e+03,  0.000e+00,  4.210e+03,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  2.418e+04,  0.000e+00,  1.622e+04,  7.019e+03],\n",
      "       [ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00],\n",
      "       [ 1.305e-01,  0.000e+00,  7.926e-02,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  7.373e-01,  0.000e+00,  3.423e-01,  1.625e-01],\n",
      "       [-2.693e+02,  0.000e+00, -1.863e+02,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -1.080e+03,  0.000e+00, -7.207e+02, -3.143e+02],\n",
      "       [-2.655e+02,  0.000e+00, -1.836e+02,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00, -1.045e+03,  0.000e+00, -7.074e+02, -3.023e+02],\n",
      "       [ 5.604e+02,  0.000e+00,  3.870e+02,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  2.233e+03,  0.000e+00,  1.494e+03,  6.456e+02],\n",
      "       [ 2.980e+02,  0.000e+00,  2.109e+02,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  1.219e+03,  0.000e+00,  8.109e+02,  3.530e+02],\n",
      "       [ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00],\n",
      "       [ 0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
      "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00]])\n",
      "Db = array([[-1.878e+02],\n",
      "       [ 2.993e+03],\n",
      "       [ 0.000e+00],\n",
      "       [ 6.307e-02],\n",
      "       [-1.338e+02],\n",
      "       [-1.302e+02],\n",
      "       [ 2.742e+02],\n",
      "       [ 1.484e+02],\n",
      "       [ 0.000e+00],\n",
      "       [ 0.000e+00]])\n",
      "layer_index = 5, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[  1.38 ,   2.197,   2.494, ...,   1.795,   2.045,   1.795],\n",
      "       [ -0.662,  -0.761,  -1.04 , ...,  -1.058,  -0.995,  -0.729],\n",
      "       [  1.427,   1.575,   1.479, ...,   1.59 ,   1.591,   1.138],\n",
      "       ...,\n",
      "       [-10.121, -13.166, -15.021, ..., -13.302, -14.044, -12.007],\n",
      "       [  4.879,   5.873,   5.865, ...,   5.753,   5.827,   4.625],\n",
      "       [  1.945,   1.994,   2.559, ...,   2.092,   2.926,   2.013]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[ True,  True,  True, ...,  True,  True,  True],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       ...,\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True]])\n",
      "DZ = array([[ 73.377,  14.616,  73.377, ...,  21.115,   6.444,  41.105],\n",
      "       [ -0.   ,  -0.   ,  -0.   , ...,  -0.   ,  -0.   ,  -0.   ],\n",
      "       [ -7.064,  -0.989,  -7.064, ...,  -2.028,  -0.284,  -3.964],\n",
      "       ...,\n",
      "       [  0.   ,   0.   ,   0.   , ...,   0.   ,   0.   ,   0.   ],\n",
      "       [ 47.553,   9.488,  47.553, ...,  14.144,   4.283,  26.383],\n",
      "       [-12.264,  -2.484, -12.264, ...,  -3.103,  -1.132,  -7.089]])\n",
      "layer_index = 6, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0.51 , 0.547, 0.484, ..., 0.961, 0.219, 0.642],\n",
      "       [0.426, 0.609, 0.388, ..., 0.356, 0.738, 0.189],\n",
      "       [0.078, 0.052, 0.799, ..., 0.351, 0.931, 0.367],\n",
      "       [0.01 , 0.289, 0.596, ..., 0.079, 0.232, 0.788],\n",
      "       [0.379, 0.876, 0.756, ..., 0.657, 0.705, 0.009]])\n",
      "DA = array([[146.393,  26.174, 146.393, ...,  41.25 ,  10.847,  82.374],\n",
      "       [ 64.888,  11.888,  64.888, ...,  18.878,   5.054,  36.2  ],\n",
      "       [100.012,  17.55 , 100.012, ...,  28.431,   7.133,  56.144],\n",
      "       [169.216,  31.358, 169.216, ...,  47.913,  13.229,  95.14 ],\n",
      "       [174.569,  34.21 , 174.569, ...,  50.61 ,  15.084,  97.554]])\n",
      "DW = array([[5762.006, 5828.048, 5800.11 , 5934.795, 5401.454],\n",
      "       [   0.   ,    0.   ,    0.   ,    0.   ,    0.   ],\n",
      "       [-532.94 , -536.532, -536.606, -544.788, -498.021],\n",
      "       [   0.   ,    0.   ,    0.   ,    0.   ,    0.   ],\n",
      "       [   0.   ,    0.   ,    0.   ,    0.   ,    0.   ],\n",
      "       [   0.   ,    0.   ,    0.   ,    0.   ,    0.   ],\n",
      "       [2187.566, 2208.906, 2201.59 , 2246.633, 2045.877],\n",
      "       [   0.   ,    0.   ,    0.   ,    0.   ,    0.   ],\n",
      "       [3762.651, 3806.036, 3790.114, 3874.75 , 3528.146],\n",
      "       [-937.336, -949.687, -940.989, -966.983, -875.802]])\n",
      "Db = array([[11545.856],\n",
      "       [    0.   ],\n",
      "       [-1064.969],\n",
      "       [    0.   ],\n",
      "       [    0.   ],\n",
      "       [    0.   ],\n",
      "       [ 4379.879],\n",
      "       [    0.   ],\n",
      "       [ 7537.423],\n",
      "       [-1880.977]])\n",
      "14.183924172843321\n",
      "[[   0.       0.       0.    ...    0.       0.       0.   ]\n",
      " [   0.       0.       0.    ...    0.       0.       0.   ]\n",
      " [1803.079 2306.146 2662.136 ... 2328.363 2556.222 2139.582]\n",
      " ...\n",
      " [   0.       0.       0.    ...    0.       0.       0.   ]\n",
      " [   0.       0.       0.    ...    0.       0.       0.   ]\n",
      " [3180.995 4069.157 4695.306 ... 4104.123 4507.743 3778.07 ]]\n",
      "[[1.867e+06 2.388e+06 2.755e+06 ... 2.409e+06 2.646e+06 2.217e+06]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [4.689e+02 6.028e+02 6.972e+02 ... 6.081e+02 6.689e+02 5.588e+02]\n",
      " ...\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [2.360e+03 3.019e+03 3.485e+03 ... 3.046e+03 3.345e+03 2.803e+03]\n",
      " [8.346e+02 1.069e+03 1.235e+03 ... 1.078e+03 1.185e+03 9.932e+02]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Softmax - deriv_loss\n",
      "Y_hat  = array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.]])\n",
      "DZ = array([[ 0., -1.,  0., ...,  0.,  0.,  0.],\n",
      "       [-1.,  0., -1., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 1.,  1.,  1., ...,  1.,  1.,  1.]])\n",
      "layer_index = 2, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[1.867e+06, 2.388e+06, 2.755e+06, ..., 2.409e+06, 2.646e+06,\n",
      "        2.217e+06],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       [4.689e+02, 6.028e+02, 6.972e+02, ..., 6.081e+02, 6.689e+02,\n",
      "        5.588e+02],\n",
      "       ...,\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "        0.000e+00],\n",
      "       [2.360e+03, 3.019e+03, 3.485e+03, ..., 3.046e+03, 3.345e+03,\n",
      "        2.803e+03],\n",
      "       [8.346e+02, 1.069e+03, 1.235e+03, ..., 1.078e+03, 1.185e+03,\n",
      "        9.932e+02]])\n",
      "DA = array([[ 2.013e+01,  1.932e+01,  2.013e+01, ...,  2.260e+01,  1.441e+01,\n",
      "         2.220e+01],\n",
      "       [ 4.715e+02,  4.086e+02,  4.715e+02, ...,  4.704e+02,  3.201e+02,\n",
      "         4.686e+02],\n",
      "       [ 3.002e+01,  2.812e+00,  3.002e+01, ...,  6.208e+00, -4.359e+00,\n",
      "         1.430e+01],\n",
      "       ...,\n",
      "       [ 4.262e-01,  1.079e+00,  4.262e-01, ...,  2.113e+00,  6.493e-01,\n",
      "         2.223e+00],\n",
      "       [ 5.198e+00, -2.293e-01,  5.198e+00, ...,  1.764e+00,  5.746e-01,\n",
      "         3.290e+00],\n",
      "       [ 2.800e+01,  3.980e+00,  2.800e+01, ...,  8.071e+00,  1.570e+00,\n",
      "         1.682e+01]])\n",
      "DW = array([[-1.205e+08,  0.000e+00, -3.045e+04, -3.673e+04, -8.629e+07,\n",
      "        -8.350e+07,  0.000e+00,  0.000e+00, -1.524e+05, -5.401e+04],\n",
      "       [-1.173e+08,  0.000e+00, -2.964e+04, -3.575e+04, -8.400e+07,\n",
      "        -8.128e+07,  0.000e+00,  0.000e+00, -1.484e+05, -5.257e+04],\n",
      "       [-1.532e+08,  0.000e+00, -3.870e+04, -4.668e+04, -1.097e+08,\n",
      "        -1.061e+08,  0.000e+00,  0.000e+00, -1.937e+05, -6.864e+04],\n",
      "       [-1.288e+08,  0.000e+00, -3.252e+04, -3.926e+04, -9.223e+07,\n",
      "        -8.925e+07,  0.000e+00,  0.000e+00, -1.629e+05, -5.772e+04],\n",
      "       [-1.051e+08,  0.000e+00, -2.653e+04, -3.201e+04, -7.522e+07,\n",
      "        -7.278e+07,  0.000e+00,  0.000e+00, -1.329e+05, -4.705e+04],\n",
      "       [-1.170e+08,  0.000e+00, -2.955e+04, -3.567e+04, -8.380e+07,\n",
      "        -8.109e+07,  0.000e+00,  0.000e+00, -1.480e+05, -5.244e+04],\n",
      "       [-1.167e+08,  0.000e+00, -2.947e+04, -3.555e+04, -8.352e+07,\n",
      "        -8.082e+07,  0.000e+00,  0.000e+00, -1.475e+05, -5.227e+04],\n",
      "       [-1.298e+08,  0.000e+00, -3.280e+04, -3.956e+04, -9.294e+07,\n",
      "        -8.993e+07,  0.000e+00,  0.000e+00, -1.642e+05, -5.817e+04],\n",
      "       [-9.793e+07,  0.000e+00, -2.475e+04, -2.984e+04, -7.011e+07,\n",
      "        -6.784e+07,  0.000e+00,  0.000e+00, -1.238e+05, -4.388e+04],\n",
      "       [ 1.086e+09,  0.000e+00,  2.744e+05,  3.310e+05,  7.778e+08,\n",
      "         7.526e+08,  0.000e+00,  0.000e+00,  1.374e+06,  4.867e+05]])\n",
      "Db = array([[-48.],\n",
      "       [-47.],\n",
      "       [-62.],\n",
      "       [-54.],\n",
      "       [-43.],\n",
      "       [-49.],\n",
      "       [-47.],\n",
      "       [-52.],\n",
      "       [-38.],\n",
      "       [440.]])\n",
      "layer_index = 3, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[ 1.867e+06,  2.388e+06,  2.755e+06, ...,  2.409e+06,  2.646e+06,\n",
      "         2.217e+06],\n",
      "       [-2.992e+07, -3.827e+07, -4.417e+07, ..., -3.861e+07, -4.241e+07,\n",
      "        -3.553e+07],\n",
      "       [ 4.689e+02,  6.028e+02,  6.972e+02, ...,  6.081e+02,  6.689e+02,\n",
      "         5.588e+02],\n",
      "       ...,\n",
      "       [-1.503e+06, -1.923e+06, -2.219e+06, ..., -1.940e+06, -2.130e+06,\n",
      "        -1.785e+06],\n",
      "       [ 2.360e+03,  3.019e+03,  3.485e+03, ...,  3.046e+03,  3.345e+03,\n",
      "         2.803e+03],\n",
      "       [ 8.346e+02,  1.069e+03,  1.235e+03, ...,  1.078e+03,  1.185e+03,\n",
      "         9.932e+02]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[ True,  True,  True, ...,  True,  True,  True],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       ...,\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ...,  True,  True,  True]])\n",
      "DZ = array([[20.128, 19.318, 20.128, ..., 22.595, 14.408, 22.203],\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "       [30.025,  2.812, 30.025, ...,  6.208, -4.359, 14.3  ],\n",
      "       ...,\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "       [ 5.198, -0.229,  5.198, ...,  1.764,  0.575,  3.29 ],\n",
      "       [27.996,  3.98 , 27.996, ...,  8.071,  1.57 , 16.825]])\n",
      "layer_index = 4, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ],\n",
      "       [   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ],\n",
      "       [1803.079, 2306.146, 2662.136, ..., 2328.363, 2556.222, 2139.582],\n",
      "       ...,\n",
      "       [   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ],\n",
      "       [   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ],\n",
      "       [3180.995, 4069.157, 4695.306, ..., 4104.123, 4507.743, 3778.07 ]])\n",
      "DA = array([[ 1.321e+04,  1.378e+04,  1.321e+04, ...,  1.748e+04,  1.239e+04,\n",
      "         1.841e+04],\n",
      "       [ 4.206e-01, -1.005e+01,  4.206e-01, ..., -1.210e+01, -1.222e+01,\n",
      "        -1.033e+01],\n",
      "       [ 9.486e+03,  9.561e+03,  9.486e+03, ...,  1.216e+04,  8.533e+03,\n",
      "         1.291e+04],\n",
      "       ...,\n",
      "       [-1.134e+02, -1.990e+01, -1.134e+02, ..., -3.487e+01,  4.643e+00,\n",
      "        -6.338e+01],\n",
      "       [ 3.634e+04,  3.690e+04,  3.634e+04, ...,  4.690e+04,  3.299e+04,\n",
      "         4.972e+04],\n",
      "       [ 1.578e+04,  1.589e+04,  1.578e+04, ...,  2.022e+04,  1.418e+04,\n",
      "         2.149e+04]])\n",
      "DW = array([[0.000e+00, 0.000e+00, 1.522e+08, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 2.685e+08],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 7.770e+06, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 1.371e+07],\n",
      "       [0.000e+00, 0.000e+00, 4.187e+05, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 7.390e+05],\n",
      "       [0.000e+00, 0.000e+00, 1.186e+08, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 2.092e+08],\n",
      "       [0.000e+00, 0.000e+00, 1.431e+08, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 2.525e+08],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 1.722e+06, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 3.039e+06],\n",
      "       [0.000e+00, 0.000e+00, 9.531e+06, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 1.682e+07]])\n",
      "Db = array([[63743.607],\n",
      "       [    0.   ],\n",
      "       [ 3252.695],\n",
      "       [  175.413],\n",
      "       [49691.379],\n",
      "       [59962.643],\n",
      "       [    0.   ],\n",
      "       [    0.   ],\n",
      "       [  724.818],\n",
      "       [ 4004.355]])\n",
      "layer_index = 5, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[-1.953e+04, -2.499e+04, -2.884e+04, ..., -2.521e+04, -2.769e+04,\n",
      "        -2.319e+04],\n",
      "       [-6.625e-01, -7.611e-01, -1.040e+00, ..., -1.058e+00, -9.953e-01,\n",
      "        -7.290e-01],\n",
      "       [ 1.803e+03,  2.306e+03,  2.662e+03, ...,  2.328e+03,  2.556e+03,\n",
      "         2.140e+03],\n",
      "       ...,\n",
      "       [-1.012e+01, -1.317e+01, -1.502e+01, ..., -1.330e+01, -1.404e+01,\n",
      "        -1.201e+01],\n",
      "       [-1.275e+04, -1.631e+04, -1.883e+04, ..., -1.646e+04, -1.808e+04,\n",
      "        -1.514e+04],\n",
      "       [ 3.181e+03,  4.069e+03,  4.695e+03, ...,  4.104e+03,  4.508e+03,\n",
      "         3.778e+03]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ...,  True,  True,  True],\n",
      "       ...,\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ...,  True,  True,  True]])\n",
      "DZ = array([[    0.   ,     0.   ,     0.   , ...,     0.   ,     0.   ,\n",
      "            0.   ],\n",
      "       [    0.   ,    -0.   ,     0.   , ...,    -0.   ,    -0.   ,\n",
      "           -0.   ],\n",
      "       [ 9485.733,  9561.338,  9485.733, ..., 12159.372,  8532.786,\n",
      "        12910.332],\n",
      "       ...,\n",
      "       [   -0.   ,    -0.   ,    -0.   , ...,    -0.   ,     0.   ,\n",
      "           -0.   ],\n",
      "       [    0.   ,     0.   ,     0.   , ...,     0.   ,     0.   ,\n",
      "            0.   ],\n",
      "       [15783.008, 15886.483, 15783.008, ..., 20219.977, 14182.129,\n",
      "        21490.405]])\n",
      "layer_index = 6, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0.51 , 0.547, 0.484, ..., 0.961, 0.219, 0.642],\n",
      "       [0.426, 0.609, 0.388, ..., 0.356, 0.738, 0.189],\n",
      "       [0.078, 0.052, 0.799, ..., 0.351, 0.931, 0.367],\n",
      "       [0.01 , 0.289, 0.596, ..., 0.079, 0.232, 0.788],\n",
      "       [0.379, 0.876, 0.756, ..., 0.657, 0.705, 0.009]])\n",
      "DA = array([[19848596.008, 19985877.716, 19848596.008, ..., 25432217.372,\n",
      "        17840245.301, 27023192.393],\n",
      "       [20088691.146, 20227596.001, 20088691.146, ..., 25739834.339,\n",
      "        18056021.093, 27350089.44 ],\n",
      "       [19957263.245, 20095305.511, 19957263.245, ..., 25571458.524,\n",
      "        17937923.352, 27171135.418],\n",
      "       [20426505.393, 20567729.688, 20426505.393, ..., 26172670.469,\n",
      "        18359642.432, 27810019.228],\n",
      "       [18550075.335, 18678377.266, 18550075.335, ..., 23768409.721,\n",
      "        16673114.452, 25255299.827]])\n",
      "DW = array([[       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [18071476.294, 18568754.541, 18442309.057, 18690923.299,\n",
      "        18577123.322],\n",
      "       [       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [       0.   ,        0.   ,        0.   ,        0.   ,\n",
      "               0.   ],\n",
      "       [30065950.362, 30893119.393, 30682706.754, 31096260.652,\n",
      "        30907295.574]])\n",
      "Db = array([[       0.   ],\n",
      "       [       0.   ],\n",
      "       [37056138.956],\n",
      "       [       0.   ],\n",
      "       [       0.   ],\n",
      "       [       0.   ],\n",
      "       [       0.   ],\n",
      "       [       0.   ],\n",
      "       [       0.   ],\n",
      "       [61651090.299]])\n",
      "14.377341321203978\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[4.533e-009 4.533e-009 4.533e-009 ... 4.533e-009 4.533e-009 4.533e-009]\n",
      " [1.040e-030 1.040e-030 1.040e-030 ... 1.040e-030 1.040e-030 1.040e-030]\n",
      " [3.267e-209 3.267e-209 3.267e-209 ... 3.267e-209 3.267e-209 3.267e-209]\n",
      " ...\n",
      " [5.519e-010 5.519e-010 5.519e-010 ... 5.519e-010 5.519e-010 5.519e-010]\n",
      " [9.329e-018 9.329e-018 9.329e-018 ... 9.329e-018 9.329e-018 9.329e-018]\n",
      " [9.308e-213 9.308e-213 9.308e-213 ... 9.308e-213 9.308e-213 9.308e-213]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Softmax - deriv_loss\n",
      "Y_hat  = array([[4.533e-009, 4.533e-009, 4.533e-009, ..., 4.533e-009, 4.533e-009,\n",
      "        4.533e-009],\n",
      "       [1.040e-030, 1.040e-030, 1.040e-030, ..., 1.040e-030, 1.040e-030,\n",
      "        1.040e-030],\n",
      "       [3.267e-209, 3.267e-209, 3.267e-209, ..., 3.267e-209, 3.267e-209,\n",
      "        3.267e-209],\n",
      "       ...,\n",
      "       [5.519e-010, 5.519e-010, 5.519e-010, ..., 5.519e-010, 5.519e-010,\n",
      "        5.519e-010],\n",
      "       [9.329e-018, 9.329e-018, 9.329e-018, ..., 9.329e-018, 9.329e-018,\n",
      "        9.329e-018],\n",
      "       [9.308e-213, 9.308e-213, 9.308e-213, ..., 9.308e-213, 9.308e-213,\n",
      "        9.308e-213]])\n",
      "DZ = array([[ 4.533e-009, -1.000e+000,  4.533e-009, ...,  4.533e-009,\n",
      "         4.533e-009,  4.533e-009],\n",
      "       [-1.000e+000,  1.040e-030, -1.000e+000, ...,  1.040e-030,\n",
      "         1.040e-030,  1.040e-030],\n",
      "       [ 3.267e-209,  3.267e-209,  3.267e-209, ...,  3.267e-209,\n",
      "         3.267e-209,  3.267e-209],\n",
      "       ...,\n",
      "       [ 5.519e-010,  5.519e-010,  5.519e-010, ...,  5.519e-010,\n",
      "         5.519e-010,  5.519e-010],\n",
      "       [ 9.329e-018,  9.329e-018,  9.329e-018, ...,  9.329e-018,\n",
      "         9.329e-018,  9.329e-018],\n",
      "       [ 9.308e-213,  9.308e-213,  9.308e-213, ...,  9.308e-213,\n",
      "         9.308e-213,  9.308e-213]])\n",
      "layer_index = 2, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])\n",
      "DA = array([[ 1.150e+07,  8.294e+06,  1.150e+07, ...,  1.216e+07, -3.705e-02,\n",
      "         1.178e+07],\n",
      "       [ 1.514e+02,  8.843e+01,  1.514e+02, ...,  1.502e+02, -3.889e-07,\n",
      "         1.484e+02],\n",
      "       [ 2.915e+03,  2.074e+03,  2.915e+03, ...,  3.062e+03, -9.257e-06,\n",
      "         2.992e+03],\n",
      "       ...,\n",
      "       [-2.230e-01,  4.293e-01, -2.230e-01, ...,  1.463e+00, -2.598e-09,\n",
      "         1.573e+00],\n",
      "       [ 1.455e+04,  1.049e+04,  1.455e+04, ...,  1.539e+04, -4.684e-05,\n",
      "         1.490e+04],\n",
      "       [ 5.174e+03,  3.709e+03,  5.174e+03, ...,  5.457e+03, -1.657e-05,\n",
      "         5.298e+03]])\n",
      "DW = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Db = array([[-48.],\n",
      "       [-47.],\n",
      "       [-62.],\n",
      "       [446.],\n",
      "       [-43.],\n",
      "       [-49.],\n",
      "       [-47.],\n",
      "       [-52.],\n",
      "       [-38.],\n",
      "       [-60.]])\n",
      "layer_index = 3, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[-63556.025, -63556.025, -63556.025, ..., -63556.025, -63556.025,\n",
      "        -63556.025],\n",
      "       [ -2990.354,  -2990.354,  -2990.354, ...,  -2990.354,  -2990.354,\n",
      "         -2990.354],\n",
      "       [ -3263.41 ,  -3263.41 ,  -3263.41 , ...,  -3263.41 ,  -3263.41 ,\n",
      "         -3263.41 ],\n",
      "       ...,\n",
      "       [  -148.587,   -148.587,   -148.587, ...,   -148.587,   -148.587,\n",
      "          -148.587],\n",
      "       [  -725.835,   -725.835,   -725.835, ...,   -725.835,   -725.835,\n",
      "          -725.835],\n",
      "       [ -4010.389,  -4010.389,  -4010.389, ...,  -4010.389,  -4010.389,\n",
      "         -4010.389]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       ...,\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False]])\n",
      "DZ = array([[ 0.,  0.,  0., ...,  0., -0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0., -0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0., -0.,  0.],\n",
      "       ...,\n",
      "       [-0.,  0., -0., ...,  0., -0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0., -0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0., -0.,  0.]])\n",
      "layer_index = 4, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])\n",
      "DA = array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])\n",
      "DW = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Db = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])\n",
      "layer_index = 5, type(layer) = <class 'activation_functions.ReLU'>\n",
      "Z  = array([[-1.953e+04, -2.499e+04, -2.884e+04, ..., -2.521e+04, -2.769e+04,\n",
      "        -2.319e+04],\n",
      "       [-6.625e-01, -7.611e-01, -1.040e+00, ..., -1.058e+00, -9.953e-01,\n",
      "        -7.290e-01],\n",
      "       [-6.286e+07, -8.087e+07, -9.291e+07, ..., -8.119e+07, -8.931e+07,\n",
      "        -7.380e+07],\n",
      "       ...,\n",
      "       [-1.012e+01, -1.317e+01, -1.502e+01, ..., -1.330e+01, -1.404e+01,\n",
      "        -1.201e+01],\n",
      "       [-1.275e+04, -1.631e+04, -1.883e+04, ..., -1.646e+04, -1.808e+04,\n",
      "        -1.514e+04],\n",
      "       [-1.046e+08, -1.345e+08, -1.546e+08, ..., -1.351e+08, -1.486e+08,\n",
      "        -1.228e+08]])\n",
      "calculating DZ\n",
      "Rectified Linear Unit - deriv_loss\n",
      "dZ = array([[False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       ...,\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False],\n",
      "       [False, False, False, ..., False, False, False]])\n",
      "DZ = array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])\n",
      "layer_index = 6, type(layer) = <class 'weights.Transformation'>\n",
      "A  = array([[0.51 , 0.547, 0.484, ..., 0.961, 0.219, 0.642],\n",
      "       [0.426, 0.609, 0.388, ..., 0.356, 0.738, 0.189],\n",
      "       [0.078, 0.052, 0.799, ..., 0.351, 0.931, 0.367],\n",
      "       [0.01 , 0.289, 0.596, ..., 0.079, 0.232, 0.788],\n",
      "       [0.379, 0.876, 0.756, ..., 0.657, 0.705, 0.009]])\n",
      "DA = array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])\n",
      "DW = array([[0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.]])\n",
      "Db = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])\n"
     ]
    }
   ],
   "source": [
    "from loss_functions import CrossEntropy\n",
    "from activation_functions import ActivationLayer, Softmax, ReLU\n",
    "from weights import Transformation\n",
    "from network import Network\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "m = 500 # number of examples\n",
    "n = 10 # number of labels\n",
    "x = 5 # datapoints per example\n",
    "Y = np.zeros((n,m))\n",
    "Y[np.random.randint(low=n,size=m),range(m)] = 1\n",
    "X = np.random.rand(x,m)\n",
    "\n",
    "print(f\"{Y.shape = }\")\n",
    "print(f\"{X.shape = }\")\n",
    "\n",
    "\n",
    "\n",
    "network = Network(data = X, Y=Y, Loss = CrossEntropy)\n",
    "network.add_layer(ReLU, 10)\n",
    "network.add_layer(ReLU, 10)\n",
    "network.add_layer(Softmax, n)\n",
    "network.initialize()\n",
    "\n",
    "lr = 1\n",
    "for _ in range(4):\n",
    "    vals, loss = network.forward_pass()\n",
    "    print(loss)\n",
    "    # for val in vals:\n",
    "    #     print(val)\n",
    "    # print(vals[-9])\n",
    "    # print(vals[-7])\n",
    "    print(vals[-5])\n",
    "    print(vals[-3])\n",
    "    print(vals[-1])\n",
    "    print(Y)\n",
    "    dWs, dbs = network.backwards_propagation(vals)\n",
    "    network.update(lr=lr, dWs = dWs, dbs = dbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lukes\\OneDrive\\Documents\\coding\\nn_from_scratch\\src\\lukestest.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lukes/OneDrive/Documents/coding/nn_from_scratch/src/lukestest.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(n1)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukes/OneDrive/Documents/coding/nn_from_scratch/src/lukestest.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(n2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukes/OneDrive/Documents/coding/nn_from_scratch/src/lukestest.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmy_einsum\u001b[39m(string_rep, \u001b[39m*\u001b[39moperands):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(n1)\n",
    "print(n2)\n",
    "\n",
    "def my_einsum(string_rep, *operands):\n",
    "    ops, out = string_rep.split('->')\n",
    "    ops = ops.split(',')\n",
    "    operands = list(zip(ops,operands))\n",
    "    keys = dict()\n",
    "    for operand in operands:\n",
    "        assert len(operand[0]) == len(operand[1].shape), f\"operand problem: {operand[0]}, {operand[1]}\"\n",
    "        shape = operand[1].shape\n",
    "        for index, char in enumerate(operand[0]):\n",
    "            if char in keys:\n",
    "                assert keys[char] == shape[index], f\"charkeys problem: {keys[char]}, {shape[index]}\"\n",
    "            else:\n",
    "                keys[char] = shape[index]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "my_einsum(\"ij,jk->jk\",n1,n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(n1)\n",
    "# print()\n",
    "# print()\n",
    "# print(n2)\n",
    "# print()\n",
    "# print()\n",
    "# print(np.einsum('ik,jk->ji',n1,n2))\n",
    "# print()\n",
    "# print()\n",
    "\n",
    "# result = np.zeros((n2.shape[0],n1.shape[0]))\n",
    "# for i in range(n1.shape[0]):\n",
    "#     for k in range(n1.shape[1]):\n",
    "#         for j in range(n2.shape[0]):\n",
    "#             result[j,i] += n1[i,k] * n2[j,k]\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.31815146 0.         0.        ]\n",
      "  [0.         0.35729241 0.        ]\n",
      "  [0.         0.         0.32455613]]\n",
      "\n",
      " [[0.23422572 0.         0.        ]\n",
      "  [0.         0.27828213 0.        ]\n",
      "  [0.         0.         0.48749215]]]\n",
      "[[[0.10122035 0.1136731  0.10325801]\n",
      "  [0.1136731  0.12765787 0.11596144]\n",
      "  [0.10325801 0.11596144 0.10533668]]\n",
      "\n",
      " [[0.05486169 0.06518083 0.1141832 ]\n",
      "  [0.06518083 0.07744094 0.13566035]\n",
      "  [0.1141832  0.13566035 0.23764859]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def activate(Z: np.array):\n",
    "        # collapses 1 dim of array\n",
    "        max_Z = np.amax(Z, 1).reshape(Z.shape[0],1) # Get the row-wise maximum\n",
    "        eZ = np.exp(Z - max_Z ) # For stability\n",
    "        return eZ / eZ.sum(axis=1, keepdims=True) \n",
    "\n",
    "\n",
    "def deriv(Z):\n",
    "    softmax = activate(Z)\n",
    "    identity = np.eye(softmax.shape[-1])\n",
    "    t1 = np.zeros(softmax.shape+ (softmax.shape[-1],),dtype=np.float32)\n",
    "    t2 = np.zeros(softmax.shape+ (softmax.shape[-1],),dtype=np.float32)\n",
    "    t1 = np.einsum('ij,jk->ijk',softmax,identity)\n",
    "    print(t1)\n",
    "    t2 = np.einsum('ij,ik->ijk',softmax,softmax)\n",
    "    print(t2)\n",
    "    return t1-t2\n",
    "\n",
    "deriv(n1)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import our data\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "# DATA FROM HERE: https://pjreddie.com/projects/mnist-in-csv/\n",
    "file_test = '../data/MNIST/mnist_test.csv'\n",
    "file_train = '../data/MNIST/mnist_train.csv'\n",
    "\n",
    "\n",
    "def get_data_from_csv(file: str) -> Tuple[np.array, int, int]:\n",
    "    \"\"\"takes data from file (csv type) and returns\n",
    "    a shuffled version of the data in an np.array form,\n",
    "    along with two ints:\n",
    "    m - number of test examples\n",
    "    n - number of points per example (including integrated labels)\"\"\"\n",
    "    assert os.path.exists(file), f\"{file} does not exist\"\n",
    "\n",
    "    data = pd.read_csv(file)\n",
    "    m, n = data.shape\n",
    "    data = np.array(data)\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    return (data, m, n)\n",
    "\n",
    "\n",
    "def get_labels_and_data_1st_column(data: np.array) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"takes an np.array of data, returns (Transposed) labels (Y) and data (X)\"\"\"\n",
    "    data = data.T\n",
    "    Y = data[0]\n",
    "    X = data[1:]/255.\n",
    "    return (Y, X)\n",
    "\n",
    "\n",
    "data_test, m_test, n_test = get_data_from_csv(file_test)\n",
    "Y_test, X_test = get_labels_and_data_1st_column(data_test)\n",
    "\n",
    "data_train, m_train, n_train = get_data_from_csv(file_train)\n",
    "Y_train, X_train = get_labels_and_data_1st_column(data_train)\n",
    "\n",
    "assert n_test == n_train\n",
    "n = n_test\n",
    "m = m_test + m_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"making sure that our Y_test/Y_train are actually labels\"\"\"\n",
    "\n",
    "assert Y_test.max() == 9\n",
    "assert Y_train.max() == 9\n",
    "assert X_test[0].max() != 9\n",
    "assert X_train[0].max() != 9\n",
    "\n",
    "# display(Y_test[:100])\n",
    "# display(Y_train[:100])\n",
    "# display(X_test[500][:100])\n",
    "# display(X_train[500][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FORWARD PASS\n",
    "Give X\n",
    "A0 = X :: [784,m]\n",
    "Z1[10,m] = W1[10,784] * X[784,m] + b1[10]\n",
    "A1[10,m] = RelU(Z1[10,m])\n",
    "Z2[10,m] = W2[10,10] * A1[10,m] + b2[10]\n",
    "Y_hat[10,m] = softmax(A2[10,m])\n",
    "Receive Y_hat\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def initialize_w_b():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10,1) - 0.5\n",
    "    W2 = np.random.rand(10,10) - 0.5\n",
    "    b1 = np.random.rand(10,1) - 0.5\n",
    "    return W1, b1, W2, b1\n",
    "\n",
    "def ReLU(Z: np.array) -> np.array:\n",
    "    \"\"\"rectified linear unit activation function\"\"\"\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU_deriv(Z: np.array) -> np.array:\n",
    "    \"\"\"\"derivative of ReLU\"\"\"\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z: np.array) -> np.array:\n",
    "    # collapses 1 dimension of array\n",
    "    eZ = np.exp(Z)\n",
    "    return eZ/sum(eZ)\n",
    "\n",
    "def loss(Y, Y_hat):\n",
    "    # TODO maybe add a catch for non-batched situations\n",
    "    Y_hat = Y_hat + 0.000001\n",
    "    return -np.einsum(\"ij,ij->j\",Y, np.log(Y_hat))\n",
    "\n",
    "def forward_pass(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    Y_hat = softmax(Z2) \n",
    "    return Z1, A1, Z2, Y_hat\n",
    "\n",
    "def one_hot_encode(Y: np.array, classes = 10):\n",
    "    \"\"\"transforms an array into 1 hot encodings:\n",
    "    [0,3,2] -> [ [1,0,0,0],  [0,0,0,1],  [0,0,1,0] ]\n",
    "    Assumes that max(Y) is the highest possible enconding.\"\"\"\n",
    "    # first instantiate 0's which should be an array of len(Y) max(Y) \n",
    "    one_hot = np.zeros((Y.size,classes))\n",
    "    one_hot[np.arange(Y.size), Y] = 1\n",
    "    one_hot = one_hot.T\n",
    "    return one_hot\n",
    "\n",
    "# Y = one_hot_encode(Y)\n",
    "\n",
    "Y = Y_train\n",
    "X = X_train\n",
    "Z1, A1, Z2, Y_hat = forward_pass(X[:,1, None], W1, b1, W2, b2)\n",
    "print(np.sum(Y_hat,axis=1))\n",
    "\n",
    "\"\"\"\n",
    "    key:\n",
    "    VAR{a,b,...} | indicates that VAR has dimensions a x b x ...\n",
    "    VAR[i,j,...] | indicates the array or value at coordinates (i, j, ...) in VAR\n",
    "    \n",
    "    n = number of possible encodings # in general, n can change through a network,\n",
    "        but we're assuming that n is used for encodings and also layer size\n",
    "        in this example\n",
    "    m = number of inputs, batch size\n",
    "    x = number of datapoints per input\n",
    "\n",
    "(1)     X{x,m}  = Input - m examples of x data points\n",
    "(2)     Y{n,m}  = one-hot encoding of results: e.g. [[0,0,0,1,0,0], ... ] (with m encodings)\n",
    "(3)     W1{n,x} = weights applied to X\n",
    "(4)     b1{n,1} = biases applied to values going into Z1_n\n",
    "(5)     Z1{n,m} = pre-activation function values = W1{n,x} dot X{x,m} + b1{n,1}\n",
    "(6)     A1{n,m} = ReLU(Z1{n,m})\n",
    "(7)     W2{n,n} = weights applied to A1\n",
    "(8)     b2{n,1} = biases applied to values going into Z2_n\n",
    "(9)     Z2{n,m} = pre-softmax function values = W2{n,n} dot A1{n,m} + b2{n,1}\n",
    "(10)    Y_hat{n,m} = the estimate of Y = softmax(Z2{n,m})\n",
    "    \n",
    "    The forward pass looks like:\n",
    "    X * W1 + b1 = Z1\n",
    "    ReLU(Z1) = A1\n",
    "    A1 * W2 + b2 = Z2\n",
    "    softmax(Z2) = Y_hat\n",
    "\n",
    "    definition: Loss = L{m} = [L_0, L_1, ..., L_m] \n",
    "        = - sum over i of Y[i]*ln(Y_hat[i]) = -np.einsum(\"ij,ij->j\",Y, np.log(Y_hat))\n",
    "(11)    L{m} = -np.einsum(\"ij,ij->j\",Y, np.log(Y_hat))\n",
    "    def loss(Y, Y_hat):\n",
    "        return -np.einsum(\"ij,ij->j\",Y, np.log(Y_hat))\n",
    "    We set this loss specifically so that the derivative works out nicely\n",
    "\n",
    "\n",
    "    To minimize L, we want to see how L will change with respect to the variables\n",
    "    that we can control, namely W1, b1, W2, and b2.\n",
    "    \n",
    "    To calculate DW2 (dL/dW2), we use the chain rule:\n",
    "    DW2 = dL/dW2 = dL/dY_hat * dY_hat/dZ2 * dZ2/dW2\n",
    "    similarly for Db2:\n",
    "    Db2 = dL/db2 = dL/dY_hat * dY_hat/dZ2 * dZ2/db2\n",
    "    \n",
    "    But to calculate DW1 (dL/dW1), it is a little longer\n",
    "    DW1 = dL/dW1 = dL/dY_hat * dY_hat/dZ2 * dZ2/dA1 * dA1/dZ1 * dZ1/dW1\n",
    "    similarly for Db1:\n",
    "    Db1 = dL/db1 = dL/dY_hat * dY_hat/dZ2 * dZ2/dA1 * dA1/dZ1 * dZ1/db1\n",
    "\n",
    "    Now, let's start calculating each of these constituative derivatives.\n",
    "\n",
    "\n",
    "    dL/dY_hat:\n",
    "    dL/dY_hat.shape should be {n,m}\n",
    "    from (11)    L{m} = -np.dot(Y, np.log(Y_hat)):\n",
    "(12)    dL/dY_hat{n,m} = - {sum over i of} (Y[i] / Y_hat[i])\n",
    "    This shows us the opposite of exactly how Y_hat should change in order to minimize loss \n",
    "    across the n estimates for each of the m examples.\n",
    "\n",
    "\n",
    "    dY_hat/dZ2:\n",
    "    dY_hat/dZ2.shape should be {n,m}\n",
    "    from (10)    Y_hat{n,m} = the estimate of Y = softmax(Z2{n,m}):\n",
    "    given some i,j in range(n) and k,l in range(m):\n",
    "    Y_hat[i,k] changes with respect to Z2[j,l] only when k == l\n",
    "    for simplicity, assume k=l and thus drop those terms\n",
    "    dY_hat[i]/dZ2 has dimension {n}\n",
    "    dY_hat[i]/dZ2[j] = \n",
    "        if i == j --> softmax(Z2[j])*(1-softmax(Z2[j])\n",
    "        if i != j --> -softmax(Z2[i])*softmax(Z2[j])\n",
    "    dY_hat/dZ2 has dimension [n,n] for each entry in m\n",
    "    dY_hat/dZ2[i,j,k] =\n",
    "        if i == j --> softmax(Z2[j,k])*(1-softmax(Z2[j,k])\n",
    "        if i != j --> -softmax(Z2[i,k])*softmax(Z2[j,k])\n",
    "    for simplicity, call p[i, ...] = softmax(Z2[i, ...]). Thus:\n",
    "(13)    dY_hat/dZ2[i,j,k]{n,n,m} =\n",
    "            if i == j --> p[j,k]*(1-p[j,k])\n",
    "            if i != j --> -p[i,k]*p[j,k]\n",
    "\n",
    "\n",
    "    DZ2 = dL/dZ2:\n",
    "    DZ2.shape should be {n,m}\n",
    "    DZ2 = dL/dY_hat * dY_hat/dZ2\n",
    "    for now, drop m, so L has dim 1 while Z2 has dim {n}\n",
    "    let i,j in range(n)\n",
    "    from (13)   dY_hat/dZ2[i,j,k]{n,n,m} =\n",
    "                    if i == j --> p[j,k]*(1-p[j,k])\n",
    "                    if i != j --> -p[i,k]*p[j,k]:\n",
    "    dL/dZ2[j] = sum over i of dL/dY_hat[i] * dY_hat[i]/dZ2[j]\n",
    "        = {when i == j} - Y[j]/Y_hat[j] * Y_hat[j]*(1-Y_hat[j]) \n",
    "        + {sum over i when i != j of} (- (Y[i] / Y_hat[i]) * -Y_hat[i]*Y_hat[j] )\n",
    "        = -Y[j] * (1 - Y_hat[j]) - Y_hat[j] * {sum over i when i != j of} Y[i]\n",
    "        = -Y[j] + Y[j] * Y_hat[j] - Y_hat[j] * (-Y[j] + {sum over i of} Y[i]) # added Y[j] into summation\n",
    "        = -Y[j] + Y_hat[j] * (-Y[j] - (-Y[j] + 1)) # NOTE: {sum over i of} Y[i] = 1 since \n",
    "                                                   # Y[i] = 0 for all but 1 i, where it equals 1\n",
    "        = -Y[j] + Y_hat[j] * 1 = -Y[j] + Y_hat[j]\n",
    "    Adding back in k in range(m):\n",
    "    dL/dZ2[j,k] = -Y[j,k] + Y_hat[j,k]\n",
    "(14)    DZ2{n,m} = -Y + Y_hat\n",
    "\n",
    "\n",
    "    DW2 = dL/dW2:\n",
    "    DW2 = dL/dY_hat * dY_hat/dZ2 * dZ2/dW2 = DZ2 * dZ2/dw2\n",
    "    DW2.shape should be {n,n} (not m because W2 doesn't change across examples)\n",
    "    finding dZ2/dw2{n,n}:    \n",
    "    from (9)     Z2{n,m} = W2{n,n} dot A1{n,m} + b2{n,1}\n",
    "    let i,j,k in range(n), dropping m for now\n",
    "    Z2[i] = W2[i]{n} dot A1{n} + b2[i] = {sum over j} W2[i][j] * A1[j] + b2[i]\n",
    "    dZ2[i]/dW2[j,k]{1} = 0 if i != j, else A1[k]\n",
    "    dZ2[i]/dW2[i,k]{1} = A1[k]\n",
    "    dZ2/dW2{n} = A1\n",
    "    adding m back in: for l in range(m)\n",
    "    Z2[i,l]{1} = W2[i] dot A1[l] + b2[i]\n",
    "    dZ2[i,l]/dW2[i,k]{1} = A1[k,l]\n",
    "    dZ2[l]/dW2{n} = A1[l]{n}\n",
    "    dZ2/dW2{n,m} = A1{n,m}\n",
    "    This shows what you would multiply a delta_W with to get the difference in Z2\n",
    "    had you added that delta_W to W2 and recalulated Z2 that way\n",
    "\n",
    "    Dropping m again for a moment:\n",
    "    DW2{n,n} = DZ2 * dZ2/dW2 = DZ2{n} dot A1{n}\n",
    "    The derivative of the loss with respect to particular values of W2\n",
    "    To bring m back in the picture, we have to average over all of the losses accrued\n",
    "    during the training run. Namely m training examples:\n",
    "(15)    DW2{n,n} = 1/m * DZ2 * dZ2/dw2 = 1/m * DZ2{n,m} dot A1{n,m}.T{m,n}\n",
    "\n",
    "\n",
    "    Db2 = dL/db2:\n",
    "    Db2 = dL/dY_hat * dY_hat/dZ2 * dZ2/db2 = dZ2 * dZ2/db2\n",
    "    db2.shape should be {n} \n",
    "    finding dZ2/db2{n}:\n",
    "    from (9)     Z2{n,m} = W2{n,n} dot A1{n,m} + b2{n,1}\n",
    "    let i,j in range(n), dropping m for now\n",
    "    Z2[i] = W2[i]{n} dot A1{n} + b2[i] = {sum over j} W2[i][j] * A1[j] + b2[i]\n",
    "    dZ2[i]/db2[j]{1} = 0 if i != j, else 1\n",
    "    dZ2[i]/db2[i]{1} = 1\n",
    "    dZ2/db2{n} = 1\n",
    "    adding m back in: for l in range(m)\n",
    "    Z2[i,l]{1} = W2[i] dot A1[l] + b2[i]\n",
    "    dZ2[i,l]/db2[i]{1} = 1\n",
    "    dZ2[l]/db2{n} = 1{n}\n",
    "    dZ2/db2{n} = 1{n}\n",
    "\n",
    "    Dropping m again for a moment:\n",
    "    Db2{n} = DZ2 * dZ2/db2 = DZ2{n} * 1{n} = dZ2{n}\n",
    "    The derivative of the loss with respect to particular values of b2\n",
    "    To bring m back in the picture, we have to average over all of the losses accrued\n",
    "    during the training run. Namely m training examples:\n",
    "(16)    Db2{n} = 1/m * DZ2 * dZ2/dw2 = 1/m * 1{n} dot DZ2{n,m} = 1/m * np.sum(DZ2{n,m})\n",
    "\n",
    "\n",
    "    DA1 = dL/dA1:\n",
    "    DA1 = dL/dZ2 * dZ2/dA1\n",
    "    DA2.shape should be {n,m}\n",
    "    finding dZ2/dA1:\n",
    "    from (9)     Z2{n,m} = W2{n,n} dot A1{n,m} + b2{n,1}\n",
    "    let i,j in range(n), dropping m for now\n",
    "    Z2[i] = W2[i]{n} dot A1{n} + b2[i] = {sum over j} W2[i][j] * A1[j] + b2[i]\n",
    "    dZ2[i]/dA1[j] = W2[j,i]\n",
    "    dZ2/dA1[j] = W2[j]\n",
    "    dZ2/dA1 = W2\n",
    "    adding m back in: let k,l in range(m):\n",
    "    dZ2[:,k]/dA1[:,l] = 0 if l!= k, else W2\n",
    "    dZ2[:,k]/dA1[:,k] = W2\n",
    "    dZ2/dA1{n,n} = W2{n,n}\n",
    "\n",
    "    Dropping m again for a moment:\n",
    "    DA1{n} = DZ2 * dZ2/dA1 = DZ2{n} * W2{n,n} = W2.T{n,n} dot DZ2{n}\n",
    "    The derivative of loss with respect to a particular A1 value\n",
    "    Bringing m back in the picture is easy:\n",
    "{17}    DA1{n,m} = W2.T{n,n} dot DZ2{n,m}\n",
    "\n",
    "\n",
    "    DZ1 = DL/dZ1:\n",
    "    DZ1 = dL/dA1 * dA1/dZ1\n",
    "    DZ1.shape should be {n,m}\n",
    "    finding dA1/dZ1:\n",
    "    from (6)     A1{n,m} = ReLU(Z1{n,m}):\n",
    "    ReLU is applied item-wize on Z1, so the process is simple\n",
    "    dA1/dZ1{n,m} = ReLU_deriv(Z1{n,m})\n",
    "(18)    DZ1{n,m} = DA1 * dA1/dZ1 = DA1{n,m} * ReLU_deriv(Z1{n,m})\n",
    "    We are done already, and note \"*\" is multipliaction item-wize in this formula\n",
    "\n",
    "\n",
    "    DW1 & Db1:\n",
    "    process is identical to above. Thus:\n",
    "(19)    DW1{n,x} = 1/m * DZ2{n,m} dot X{x,m}.T{m,x}\n",
    "(20)    Db1{n} = 1/m * np.sum(DZ1{n,m})\n",
    "\n",
    "\n",
    "    Now we are done!\n",
    "\n",
    "\n",
    "\n",
    "    DZ2 = -Y + Y_hat\n",
    "    # (15) DW2{n,n} = 1/m * DZ2{n,m} dot A1{n,m}.T{m,n}\n",
    "    DW2 = 1/m * np.dot(DZ2,A1.T)\n",
    "    # (16) Db2{n} = 1/m * np.sum(DZ2{n,m})\n",
    "    Db2 = 1/m * np.sum(DZ2)\n",
    "\n",
    "    # {17}    DA1{n,m} = W2.T{n,n} dot DZ2{n,m}\n",
    "    DA1 = np.dot(W2.T,DZ2)\n",
    "    # (18)    DZ1{n,m} = DA1 * dA1/dZ1 = DA1{n,m} * ReLU_deriv(Z1{n,m})\n",
    "    DZ1 = DA1 * ReLU_deriv(Z1)\n",
    "\n",
    "    # (19)    DW1{n,x} = 1/m * DZ2{n,m} dot X{x,m}.T{m,x}\n",
    "    DW1 = 1/m * np.dot(DZ1, X.T)\n",
    "    # (20)    Db1{n} = 1/m * np.sum(DZ1{n,m})\n",
    "    Db1 = 1/m * np.sum(DZ1)\n",
    "    \"\"\"\n",
    "\n",
    "    return DW1, Db1, DW2, Db2\n",
    "\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    \n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Accuracy: 0.18938648977482958\n",
      "\n",
      "Epoch 100\n",
      "Accuracy: 0.5634760579342989\n",
      "\n",
      "Epoch 200\n",
      "Accuracy: 0.7163952732545542\n",
      "\n",
      "Epoch 300\n",
      "Accuracy: 0.7698461641027351\n",
      "\n",
      "Epoch 400\n",
      "Accuracy: 0.8011633527225454\n",
      "\n",
      "Epoch 500\n",
      "Accuracy: 0.8228137135618927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "learning_rate = 0.1\n",
    "X = X_train\n",
    "Y_not_hot = Y_train\n",
    "\n",
    "Y = one_hot_encode(Y_not_hot)\n",
    "\n",
    "\n",
    "def train(X,Y,learning_rate,epochs):\n",
    "    m = X.shape[1]\n",
    "    W1, b1, W2, b2 = initialize_w_b()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        Z1, A1, Z2, Y_hat = forward_pass(X, W1, b1, W2, b2)\n",
    "        if (i+1) % (epochs//5) == 0 or not i:\n",
    "            print(f\"Epoch {i+1}\")\n",
    "            predictions = get_predictions(Y_hat)\n",
    "            print(f\"Accuracy: {get_accuracy(predictions, Y_not_hot)}\")\n",
    "            print()\n",
    "        dW1, db1, dW2, db2 = backwards_propagation(Y_hat, Y, Z2, A1, Z1, W1, b1, W2, b2, m, X)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "\n",
    "\n",
    "train(X,Y,.1, 500)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nn_from_scratch-5wfMGXWy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5740e5a6f631708b57c54ec6c0e0c4902b40036b869c78f2b20fbf3952ee788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
